{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building in H2O\n",
    "\n",
    "I will go through 4 H2O  models including linear GLM, GBM, DRF (Distributed Random Forest) and DL (Deep Learning NN).\n",
    "\n",
    "I'll use H2OFlow for the hyperparameters searching (it's just easier than writing code) and post here the best parameters found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O - GLM, GBM, NN, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "import math\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60) \n",
    "    print('Time passed: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "import time\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://localhost:54321... successful!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>17 hours 19 mins</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>22 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>LOCAL SERVICE</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>47.16 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O cluster is healthy:</td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O cluster is locked:</td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.11 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------\n",
       "H2O cluster uptime:         17 hours 19 mins\n",
       "H2O cluster version:        3.10.0.3\n",
       "H2O cluster version age:    22 days\n",
       "H2O cluster name:           LOCAL SERVICE\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    47.16 Gb\n",
       "H2O cluster total cores:    16\n",
       "H2O cluster allowed cores:  16\n",
       "H2O cluster is healthy:     True\n",
       "H2O cluster is locked:      True\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "Python version:             2.7.11 final\n",
       "--------------------------  ----------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Connect to a cluster\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Time passed: 0.0hour:0.0min:53.0sec\n"
     ]
    }
   ],
   "source": [
    "#now we load our modified train and test set\n",
    "from h2o.utils.shared_utils import _locate # private function. used to find files within h2o git project directory.\n",
    "\n",
    "tic()\n",
    "train = h2o.upload_file(path=_locate(\"./input-data/train_modified_5lags.csv\"))\n",
    "val = h2o.upload_file(path=_locate(\"./input-data/val_modified_5lags.csv\"))\n",
    "test = h2o.upload_file(path=_locate(\"./input-data/test_modified_5lags.csv\"))\n",
    "tac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# H2O python API recently (Jun 2016) added RSME as a model performance metric. So we are going to use it directly\n",
    "# into our target = log_target , to get the RSMLE\n",
    "\n",
    "def modelfit(alg, dtrain, dval, dtest, predictors, target, IDcol, filename):   \n",
    "    #Fit the algorithm on the data\n",
    "    alg.train(x=predictors, y=target, training_frame=dtrain, validation_frame=dval)\n",
    "\n",
    "    #Performance on Training and Val sets:\n",
    "    print (\"\\nModel Report\")\n",
    "    print ('RMSLE TRAIN: ', alg.model_performance(train).rmse())\n",
    "    print ('RMSLE VAL: ', alg.model_performance(val).rmse())\n",
    "    \n",
    "    #Predict on testing data: we need to revert it back to \"Demanda_uni_equil\" by applying expm1 \n",
    "    dtest[target] = alg.predict(dtest).expm1()\n",
    "    \n",
    "    print ('NUM ROWS PREDICTED: ', dtest.shape[0] )\n",
    "    #print ('NUM NEGATIVES PREDICTED: ', dtest[target][dtest[target] < 0].nrow\n",
    "    print ('MIN TARGET PREDICTED: ', dtest[target].min())\n",
    "    print ('MEAN TARGET PREDICTED: ', dtest[target].mean())\n",
    "    print ('MAX TARGET PREDICTED: ', dtest[target].max())\n",
    "    \n",
    "    dtest[target] = np.maximum(dtest[target], 0) # we make all negative numbers = 0 since there cannot be a negative demand\n",
    "   \n",
    "    #Export submission file:\n",
    "    submission = dtest[[IDcol,target]].as_data_frame(use_pandas=True)\n",
    "    submission[IDcol] = submission[IDcol].astype(int)\n",
    "    submission.rename(columns={target: 'Demanda_uni_equil'}, inplace=True)\n",
    "    submission.to_csv(\"./Submissions/\"+filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define now the target and the Id cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define target and ID columns:\n",
    "target = 'log_target'\n",
    "IDcol = 'id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alg6 - GBM\n",
    "\n",
    "Lets make our first GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model Report\n",
      "('RMSLE TRAIN: ', 0.3314411740600231)\n",
      "('RMSLE VAL: ', 0.47747733301046835)\n",
      "\n",
      "('NUM ROWS PREDICTED: ', 6999251)\n",
      "('MIN TARGET PREDICTED: ', -0.4466447822087602)"
     ]
    }
   ],
   "source": [
    "predictors = ['Agencia_ID','Canal_ID','Ruta_SAK','Cliente_ID','Producto_ID','Log_Target_mean_lag1',\n",
    "                'Log_Target_mean_lag2','Log_Target_mean_lag3','Log_Target_mean_lag4','Lags_sum','brand','cluster',\n",
    "                'Qty_Ruta_SAK_Bin','ZipCode']\n",
    "\n",
    "alg6 = H2OGradientBoostingEstimator(ntrees=300,max_depth=25,learn_rate=0.1, min_rows=10, nbins=20, \n",
    "                                    ignored_columns=[\"Semana\",\"pairs_mean\"])\n",
    "tic()\n",
    "modelfit(alg6, train, val, test, predictors, target, IDcol, 'alg6.csv')\n",
    "tac()\n",
    "\n",
    "alg6.varimp(use_pandas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> LB: 0.47600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good improvement from scikit-learn models. I still don't like the fact that RSMLE VAL is away from RSMLE TEST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alg7 - DRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "predictors = ['Agencia_ID','Canal_ID','Ruta_SAK','Cliente_ID','Producto_ID','Log_Target_mean_lag1',\n",
    "                'Log_Target_mean_lag2','Log_Target_mean_lag3','Log_Target_mean_lag4','Lags_sum','brand','cluster',\n",
    "                'Qty_Ruta_SAK_Bin','ZipCode']\n",
    "\n",
    "alg7 = H2ORandomForestEstimator(ntrees=300, max_depth=30)\n",
    "\n",
    "tic()\n",
    "modelfit(alg7, train, val, test, predictors, target, IDcol, 'alg7.csv')\n",
    "tac()\n",
    "\n",
    "alg7.varimp(use_pandas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Report<br>\n",
    "RMSLE TRAIN:  0.4428664746471727<br>\n",
    "RMSLE VAL:  0.4416625096031187\n",
    "\n",
    "NUM ROWS PREDICTED:  6999251<br>\n",
    "MIN TARGET PREDICTED:  0.020059765726462852<br>\n",
    "MEAN TARGET PREDICTED:  [5.6052535622997]<br>\n",
    "MAX TARGET PREDICTED:  2421.874184697988<br>\n",
    "Time passed: 14hour:31min:5sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> LB: 0.46515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good improvement however 14 hrs is killing me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alg8 - GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model Report\n",
      "RMSLE TRAIN:  0.6208971783764934\n",
      "RMSLE VAL:  0.6159225642176592\n",
      "\n",
      "NUM ROWS PREDICTED:  6999251\n",
      "MIN TARGET PREDICTED:  1.7312609680778603\n",
      "MEAN TARGET PREDICTED:  [5.345971839793424]\n",
      "MAX TARGET PREDICTED:  1397701.5977421915\n",
      "Warning: Method make_url in class H2OConnection is deprecated.\n",
      "Time passed: 0hour:1min:15sec\n",
      "Warning: This model doesn't have variable importances\n"
     ]
    }
   ],
   "source": [
    "predictors = ['Agencia_ID','Canal_ID','Ruta_SAK','Cliente_ID','Producto_ID','Log_Target_mean_lag1',\n",
    "                'Log_Target_mean_lag2','Log_Target_mean_lag3','Log_Target_mean_lag4','Lags_sum','brand','cluster',\n",
    "                'Qty_Ruta_SAK_Bin','ZipCode']\n",
    "\n",
    "alg8 = H2OGeneralizedLinearEstimator(Lambda=0.1, alpha=0.1, lambda_search=True, nlambdas=100,  family=\"poisson\")\n",
    "  \n",
    "tic()\n",
    "modelfit(alg8, train, val, test, predictors, target, IDcol, 'alg8.csv')\n",
    "tac()\n",
    "\n",
    "alg8.varimp(use_pandas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not even going to send this to LB. We saw before in the sckit models that Linear Regression is not that good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alg9 - DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = ['Agencia_ID','Canal_ID','Ruta_SAK','Cliente_ID','Producto_ID','Log_Target_mean_lag1',\n",
    "                'Log_Target_mean_lag2','Log_Target_mean_lag3','Log_Target_mean_lag4','Lags_sum','brand','cluster',\n",
    "                'Qty_Ruta_SAK_Bin','ZipCode']\n",
    "\n",
    "alg9 = H2ODeepLearningEstimator(hidden=[50,50,50,50], epochs=50)\n",
    "    \n",
    "tic()\n",
    "modelfit(alg9, train, val, test, predictors, target, IDcol, 'alg9.csv')\n",
    "tac()\n",
    "\n",
    "alg9.varimp(use_pandas=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
