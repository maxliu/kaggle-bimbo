{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/scirpus/grupo-bimbo-inventory-demand/ftlr-use-pypy\n",
    "\n",
    "from csv import DictReader\n",
    "from math import sqrt, log, expm1\n",
    "from datetime import datetime\n",
    "\n",
    "# TL; DR, the main training process starts on line: 250,\n",
    "# you may want to start reading the code from there\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# parameters #################################################################\n",
    "##############################################################################\n",
    "\n",
    "# A, paths\n",
    "train = './input-data/train.csv'               # path to training file\n",
    "test = './input-data/test.csv'                 # path to testing file\n",
    "submission = './Submissions/submission-FTLR.csv'  # path of to be outputted submission file\n",
    "\n",
    "# B, model\n",
    "alpha = .02  # learning rate\n",
    "beta = 1.   # smoothing parameter for adaptive learning rate\n",
    "L1 = 0.     # L1 regularization, larger value means more regularized\n",
    "L2 = 1.     # L2 regularization, larger value means more regularized\n",
    "\n",
    "# C, feature/hash trick\n",
    "D = 2 ** 23             # number of weights to use\n",
    "interaction = True     # whether to enable poly2 feature interactions\n",
    "\n",
    "# D, training/validation\n",
    "epoch = 4  # learn training data for N passes\n",
    "holdout = 9  # use week holdout validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# class, function, generator definitions #####################################\n",
    "##############################################################################\n",
    "\n",
    "class ftrl_proximal(object):\n",
    "    ''' Our main algorithm: Follow the regularized leader - proximal\n",
    "\n",
    "        In short,\n",
    "        this is an adaptive-learning-rate sparse regression with\n",
    "        efficient L1-L2-regularization\n",
    "\n",
    "        Reference:\n",
    "        http://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf\n",
    "    '''\n",
    "\n",
    "    def __init__(self, alpha, beta, L1, L2, D, interaction):\n",
    "        # parameters\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.L1 = L1\n",
    "        self.L2 = L2\n",
    "\n",
    "        # feature related parameters\n",
    "        self.D = D\n",
    "        self.interaction = interaction\n",
    "\n",
    "        # model\n",
    "        # n: squared sum of past gradients\n",
    "        # z: weights\n",
    "        # w: lazy weights\n",
    "        self.n = [0.] * D\n",
    "        self.z = [0.] * D\n",
    "        self.w = {}\n",
    "\n",
    "    def _indices(self, x):\n",
    "        ''' A helper generator that yields the indices in x\n",
    "\n",
    "            The purpose of this generator is to make the following\n",
    "            code a bit cleaner when doing feature interaction.\n",
    "        '''\n",
    "\n",
    "        # first yield index of the bias term\n",
    "        yield 0\n",
    "\n",
    "        # then yield the normal indices\n",
    "        for index in x:\n",
    "            yield index\n",
    "\n",
    "        # now yield interactions (if applicable)\n",
    "        if self.interaction:\n",
    "            D = self.D\n",
    "            L = len(x)\n",
    "            for i in range(L):\n",
    "                for j in range(i+1, L):\n",
    "                    yield abs(hash(str(x[i]) + '_' + str(x[j]))) % D\n",
    "                    for k in range(j+1, L):\n",
    "                        yield abs(hash(str(x[i]) + '_' + str(x[j]) +\n",
    "                                  '_' + str(x[k]))) % D\n",
    "                        for l in range(k+1, L):\n",
    "                            yield abs(hash(str(x[i]) + '_' + str(x[j]) +\n",
    "                                      '_' + str(x[k]) + '_' + str(x[l]))) % D\n",
    "\n",
    "    def predict(self, x):\n",
    "        ''' Get demand estimation on x\n",
    "\n",
    "            INPUT:\n",
    "                x: features\n",
    "\n",
    "            OUTPUT:\n",
    "                demand\n",
    "        '''\n",
    "\n",
    "        # parameters\n",
    "        alpha = self.alpha\n",
    "        beta = self.beta\n",
    "        L1 = self.L1\n",
    "        L2 = self.L2\n",
    "\n",
    "        # model\n",
    "        n = self.n\n",
    "        z = self.z\n",
    "        w = {}\n",
    "\n",
    "        # wTx is the inner product of w and x\n",
    "        wTx = 0.\n",
    "        for i in self._indices(x):\n",
    "            sign = -1. if z[i] < 0 else 1.  # get sign of z[i]\n",
    "\n",
    "            # build w on the fly using z and n, hence the name - lazy weights\n",
    "            # we are doing this at prediction instead of update time is because\n",
    "            # this allows us for not storing the complete w\n",
    "            if ((L1 > 0) & (sign * z[i] <= L1)):\n",
    "                # w[i] vanishes due to L1 regularization\n",
    "                w[i] = 0.\n",
    "            else:\n",
    "                # apply prediction time L1, L2 regularization to z and get w\n",
    "                w[i] = (sign * L1 - z[i]) / ((beta + sqrt(n[i])) / alpha + L2)\n",
    "\n",
    "            wTx += w[i]\n",
    "\n",
    "        # cache the current w for update stage\n",
    "        self.w = w\n",
    "\n",
    "        # Raw Output\n",
    "        return wTx\n",
    "\n",
    "    def update(self, x, p, y):\n",
    "        ''' Update model using x, p, y\n",
    "\n",
    "            INPUT:\n",
    "                x: feature, a list of indices\n",
    "                p: demand prediction of our model\n",
    "                y: answer\n",
    "\n",
    "            MODIFIES:\n",
    "                self.n: increase by squared gradient\n",
    "                self.z: weights\n",
    "        '''\n",
    "\n",
    "        # parameter\n",
    "        alpha = self.alpha\n",
    "\n",
    "        # model\n",
    "        n = self.n\n",
    "        z = self.z\n",
    "        w = self.w\n",
    "\n",
    "        # gradient under logloss\n",
    "        g = p - y\n",
    "\n",
    "        # update z and n\n",
    "        for i in self._indices(x):\n",
    "            sigma = (sqrt(n[i] + g * g) - sqrt(n[i])) / alpha\n",
    "            z[i] += g - sigma * w[i]\n",
    "            n[i] += g * g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data(path, D):\n",
    "    ''' GENERATOR: Apply hash-trick to the original csv row\n",
    "                   and for simplicity, we one-hot-encode everything\n",
    "\n",
    "        INPUT:\n",
    "            path: path to training or testing file\n",
    "            D: the max index that we can hash to\n",
    "\n",
    "        YIELDS:\n",
    "            ID: id of the instance, mainly useless\n",
    "            x: a list of hashed and one-hot-encoded 'indices'\n",
    "               we only need the index since all values are either 0 or 1\n",
    "            y: y: log(actual demand +1)\n",
    "    '''\n",
    "\n",
    "    for t, row in enumerate(DictReader(open(path))):\n",
    "        ID = 0\n",
    "        week = 0\n",
    "        y = 0.\n",
    "        if 'id' in row:\n",
    "            ID = row['id']\n",
    "            del row['id']\n",
    "        if 'Demanda_uni_equil' in row:\n",
    "            y = log(float(row['Demanda_uni_equil'])+1.)\n",
    "            del row['Demanda_uni_equil']\n",
    "        if 'Semana' in row:\n",
    "            week = int(row['Semana'])\n",
    "            del row['Semana']\n",
    "        # build x\n",
    "        x = []\n",
    "        for key in row:\n",
    "            if(key == 'Canal_ID' or key == 'Ruta_SAK' or\n",
    "               key == 'Cliente_ID' or key == 'Producto_ID' or\n",
    "               key == 'Agencia_ID'):\n",
    "                value = row[key]\n",
    "                # one-hot encode everything with hash trick\n",
    "                index = abs(hash(key + '_' + value)) % D\n",
    "                x.append(index)\n",
    "\n",
    "        yield t, week, ID, x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# start training #############################################################\n",
    "##############################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    #print('Use PYPY!!!!')\n",
    "    #print('Remove the next line!!!!')\n",
    "    #exit(0)\n",
    "    start = datetime.now()\n",
    "\n",
    "    # initialize ourselves a learner\n",
    "    learner = ftrl_proximal(alpha, beta, L1, L2, D, interaction)\n",
    "\n",
    "    # start training\n",
    "    for e in range(epoch):\n",
    "        loss = 0.\n",
    "        count = 0\n",
    "        for t, week, ID, x, y in data(train, D):  # data is a generator\n",
    "            #   t: just a instance counter\n",
    "            #   week: you know what this is\n",
    "            #   ID: id provided in original data\n",
    "            #   x: features\n",
    "            #   y: log(actual demand + 1)\n",
    "            # step 1, get prediction from learner\n",
    "            p = learner.predict(x)\n",
    "            if((t % 1000000) == 0):\n",
    "                print(t)\n",
    "\n",
    "            if ((holdout != 0) and (week >= holdout)):\n",
    "                # step 2-1, calculate validation loss\n",
    "                #           we do not train with the validation data so our\n",
    "                #           validation loss is an accurate estimation\n",
    "                #\n",
    "                # holdout: train instances from day 1 to day N -1\n",
    "                #            validate with instances from day N and after\n",
    "                #\n",
    "                loss += (max(0, p)-y)**2\n",
    "                count += 1\n",
    "            else:\n",
    "                # step 2-2, update learner with demand information\n",
    "                learner.update(x, p, y)\n",
    "\n",
    "        count = max(count, 1)\n",
    "        print('Epoch %d finished, validation RMSLE: %f, elapsed time: %s' %\n",
    "              (e, sqrt(loss/count), str(datetime.now() - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    #########################################################################\n",
    "    # start testing, and build Kaggle's submission file #####################\n",
    "    #########################################################################\n",
    "    \n",
    "    with open(submission, 'w') as outfile:\n",
    "        outfile.write('id,Demanda_uni_equil\\n')\n",
    "        for t, date, ID, x, y in data(test, D):\n",
    "            p = learner.predict(x)\n",
    "            outfile.write('%s,%.3f\\n' % (ID,\n",
    "                                         expm1(max(0, p))))\n",
    "            if((t % 100000) == 0):\n",
    "                print(t)\n",
    "    print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
