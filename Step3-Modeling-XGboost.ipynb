{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Building in XGBoost\n",
    "\n",
    "This is a great article for tunning XGboost: http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "windows=False\n",
    "if (windows):\n",
    "    mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "    os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import boto # to download from AWS S3 buckets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "import math\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60) \n",
    "    print('Time passed: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's define variables that will define the behaviour of the whole script\n",
    "s3_path = 'http://bbts-kaggle.s3.amazonaws.com/bimbo/Pablo/'\n",
    "use_validation=True # splits train data into train + val sets\n",
    "val_week_threshold = 8 # (possible values 8 or 9)  - weeks 3,4,5,6,7 are train, and week 8.9 are val\n",
    "trimmed = True # removes weeks which doesn't have all the lags. If False, fills empty lags with 0\n",
    "lag = 5  # shifted mean_demand up to \"lag\" weeks\n",
    "if (val_week_threshold == 8): lag = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading File: train_modified_holdout8_trimmed.csv  ...\n",
      "Downloading File: val_modified_holdout8_trimmed.csv  ...\n",
      "Downloading File: test_modified_holdout8_trimmed.csv  ...\n",
      "Time passed: 0hour:4min:10sec\n"
     ]
    }
   ],
   "source": [
    "#now we load our modified train and test set\n",
    "tic()\n",
    "sufix=\"\"\n",
    "if (use_validation): \n",
    "    sufix += \"_holdout\"\n",
    "    sufix += repr(val_week_threshold)\n",
    "if (trimmed): sufix += \"_trimmed\"\n",
    "\n",
    "print ('Downloading File: train_modified{}.csv  ...'.format(sufix))\n",
    "train = pd.read_csv(\"{}train_modified{}.csv\".format(s3_path,sufix),\n",
    "                    dtype = {'Canal_ID': 'int8',\n",
    "                            'brand': 'int8',\n",
    "                            'prodtype_cluster': 'int32',\n",
    "                            'Qty_Ruta_SAK_Bin': 'int32',\n",
    "                            'ZipCode': 'uint32',\n",
    "                            'week_ct': 'int8',\n",
    "                            'NombreCliente': 'int32',\n",
    "                            'Producto_ID_clust_ID':'int32',\n",
    "                            'Ruta_SAK_clust_ID':'int32',\n",
    "                            'Agencia_ID_clust_ID':'int32',\n",
    "                            'Cliente_ID_clust_ID':'int32'},\n",
    "                   )\n",
    "\n",
    "if (use_validation):\n",
    "    print ('Downloading File: val_modified{}.csv  ...'.format(sufix))\n",
    "    val = pd.read_csv(\"{}val_modified{}.csv\".format(s3_path,sufix),\n",
    "                    dtype = {'Canal_ID': 'int8',\n",
    "                            'brand': 'int8',\n",
    "                            'prodtype_cluster': 'int32',\n",
    "                            'Qty_Ruta_SAK_Bin': 'int32',\n",
    "                            'ZipCode': 'uint32',\n",
    "                            'week_ct': 'int8',\n",
    "                            'NombreCliente': 'int32',\n",
    "                            'Producto_ID_clust_ID':'int32',\n",
    "                            'Ruta_SAK_clust_ID':'int32',\n",
    "                            'Agencia_ID_clust_ID':'int32',\n",
    "                            'Cliente_ID_clust_ID':'int32'},\n",
    "                   ) \n",
    "\n",
    "print ('Downloading File: test_modified{}.csv  ...'.format(sufix))\n",
    "test = pd.read_csv(\"{}test_modified{}.csv\".format(s3_path,sufix),\n",
    "                    dtype = {'id': 'uint32',\n",
    "                            'Canal_ID': 'int8',\n",
    "                            'brand': 'int8',\n",
    "                            'prodtype_cluster': 'int32',\n",
    "                            'Qty_Ruta_SAK_Bin': 'int32',\n",
    "                            'ZipCode': 'uint32',\n",
    "                            'week_ct': 'int8',\n",
    "                            'NombreCliente': 'int32',\n",
    "                            'Producto_ID_clust_ID':'int32',\n",
    "                            'Ruta_SAK_clust_ID':'int32',\n",
    "                            'Agencia_ID_clust_ID':'int32',\n",
    "                            'Cliente_ID_clust_ID':'int32'},\n",
    "                      )\n",
    "tac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define target and ID columns:\n",
    "target = 'log_target'\n",
    "IDcol = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>log_target</th>\n",
       "      <th>pairs_mean</th>\n",
       "      <th>Log_Target_mean_lag1</th>\n",
       "      <th>Log_Target_mean_lag2</th>\n",
       "      <th>...</th>\n",
       "      <th>brand</th>\n",
       "      <th>prodtype_cluster</th>\n",
       "      <th>Qty_Ruta_SAK_Bin</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>week_ct</th>\n",
       "      <th>NombreCliente</th>\n",
       "      <th>Producto_ID_clust_ID</th>\n",
       "      <th>Ruta_SAK_clust_ID</th>\n",
       "      <th>Agencia_ID_clust_ID</th>\n",
       "      <th>Cliente_ID_clust_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.138243</td>\n",
       "      <td>0.128988</td>\n",
       "      <td>0.081382</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1238</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.138243</td>\n",
       "      <td>0.128988</td>\n",
       "      <td>0.128988</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1238</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.138243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128988</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1240</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.230405</td>\n",
       "      <td>0.257975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1240</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.230405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257975</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       8        1110         7      3301       15766         1216   \n",
       "1       8        1110         7      3301       15766         1238   \n",
       "2       9        1110         7      3301       15766         1238   \n",
       "3       8        1110         7      3301       15766         1240   \n",
       "4       9        1110         7      3301       15766         1240   \n",
       "\n",
       "   log_target  pairs_mean  Log_Target_mean_lag1  Log_Target_mean_lag2  \\\n",
       "0    1.791759    0.138243              0.128988              0.081382   \n",
       "1    1.386294    0.138243              0.128988              0.128988   \n",
       "2    1.098612    0.138243              0.000000              0.128988   \n",
       "3    1.098612    0.230405              0.257975              0.000000   \n",
       "4    1.098612    0.230405              0.000000              0.257975   \n",
       "\n",
       "          ...           brand  prodtype_cluster  Qty_Ruta_SAK_Bin  ZipCode  \\\n",
       "0         ...               1                 2                 1     2008   \n",
       "1         ...               1                 2                 1     2008   \n",
       "2         ...               1                 2                 1     2008   \n",
       "3         ...               1                14                 1     2008   \n",
       "4         ...               1                14                 1     2008   \n",
       "\n",
       "   week_ct  NombreCliente  Producto_ID_clust_ID  Ruta_SAK_clust_ID  \\\n",
       "0        0             11                    20                 68   \n",
       "1        0             11                    20                 68   \n",
       "2        1             11                    20                 68   \n",
       "3        0             11                    24                 68   \n",
       "4        1             11                    24                 68   \n",
       "\n",
       "   Agencia_ID_clust_ID  Cliente_ID_clust_ID  \n",
       "0                    5                  100  \n",
       "1                    5                  100  \n",
       "2                    5                  100  \n",
       "3                    5                  100  \n",
       "4                    5                  100  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val.pop('predictions')\n",
    "val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train multiple models per client cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we said on our prior step (Models wiht scikit-learn) that we need to deal with the data set high variance. Let's do this first:\n",
    "\n",
    "Looking at the plot below, created on the clustering-by-demand on the feature engineering notebook, we see that some client cluster's demand behave very differntly from others. So this explain why our model is failing on predicting accurately for all of them.\n",
    "We are going then to create a wrapper function to create as many models as Client Clusters by demand are (Cliente_ID_clust_ID). Let's see if the scores are bettter individually, and if the concatenation of all 300 models yields a better overall RSMLE than our baseline 0.47.\n",
    "\n",
    "In order to do this, we are going to create a wrapper function called clusters_fit , who is going to iterate over all cluster and call model_fit in all of them. At the end it concatenates de results.\n",
    "\n",
    "![Image of Variables vs Hypothesis](./input-data/h2o-clustByDem_Cliente_ID_400.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def model_fit(alg, ctrain, cval, ctest, predictors, target, IDcol):\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    watchlist = [(cval[predictors], cval[target])]\n",
    "    alg.fit(ctrain[predictors], ctrain[target], eval_set=watchlist, eval_metric='rmse', early_stopping_rounds=20, verbose=False)\n",
    "\n",
    "\n",
    "    #Predict training set:\n",
    "    ctrain[\"predictions\"] = alg.predict(ctrain[predictors])\n",
    "    ctrain[\"predictions\"] = np.maximum(ctrain[\"predictions\"], 0)\n",
    "\n",
    "    \n",
    "    #Predict validation (holdout) set:\n",
    "    cval[\"predictions\"] = alg.predict(cval[predictors])\n",
    "    cval[\"predictions\"] = np.maximum(cval[\"predictions\"], 0)# we make all negative numbers = 0 since there cannot be a negative demand\n",
    "\n",
    "    \n",
    "    #Predict on testing data: we need to revert it back to target by applying expm1\n",
    "    ctest[target] = alg.predict(ctest[predictors])\n",
    "    ctest[target] = np.maximum(ctest[target], 0) # we make all negative numbers = 0 since there cannot be a negative demand\n",
    "    \n",
    "    return ctrain[[target,\"predictions\"]], cval[[target,\"predictions\"]], ctest[[IDcol,target]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import sys\n",
    "def clusters_fit (alg, dtrain, dval, dtest, predictors, target, IDcol):\n",
    "    \n",
    "    train_predictions = pd.DataFrame(index=[target,\"predictions\"])\n",
    "    val_predictions = pd.DataFrame(index=[target,\"predictions\"])\n",
    "    test_predictions = pd.DataFrame(index=[IDcol,target])\n",
    "    \n",
    "    clusters_list = train.Cliente_ID_clust_ID.drop_duplicates().get_values()\n",
    "    np.random.shuffle(clusters_list)\n",
    "    \n",
    "    lcluster = 0;\n",
    "    \n",
    "    for cluster in tqdm.tqdm(clusters_list):  #tqdm is a genius progress bar library to print out progress\n",
    "        \n",
    "        #we get the cluster train,val, test data\n",
    "\n",
    "        ctrain = dtrain.loc[dtrain[\"Cliente_ID_clust_ID\"] == cluster]\n",
    "        cval   = dval.loc[dval[\"Cliente_ID_clust_ID\"] == cluster]\n",
    "        ctest  = dtest.loc[dtest[\"Cliente_ID_clust_ID\"] == cluster]\n",
    "        \n",
    "        #sys.stdout.write('\\rCluster: {:.0f}'.format(cluster))\n",
    "        \n",
    "        #we train the cluster\n",
    "        ctrain, cval, ctest = model_fit(model, ctrain, cval, ctest, predictors, target, IDcol)\n",
    "        \n",
    "        #rsmle_train =  np.sqrt(metrics.mean_squared_error(ctrain[target], ctrain[\"predictions\"]))\n",
    "        #rsmle_val = np.sqrt(metrics.mean_squared_error(cval[target], cval[\"predictions\"]))\n",
    "            \n",
    "        #concatenate each cluster result\n",
    "        train_predictions = pd.concat([train_predictions,ctrain],ignore_index=True)\n",
    "        val_predictions = pd.concat([val_predictions,cval],ignore_index=True)\n",
    "        test_predictions = pd.concat([test_predictions,ctest],ignore_index=True)\n",
    "        \n",
    "        #train_predictions.dropna(axis=0, how='any',inplace=True)\n",
    "        #val_predictions.dropna(axis=0, how='any',inplace=True)\n",
    "        #test_predictions.dropna(axis=0, how='any',inplace=True)\n",
    "          \n",
    "        #acc_rsmle_train =  np.sqrt(metrics.mean_squared_error(train_predictions[target], train_predictions[\"predictions\"]))\n",
    "        #acc_rsmle_val = np.sqrt(metrics.mean_squared_error(val_predictions[target], val_predictions[\"predictions\"]))\n",
    "        #rows_pct = cval.shape[0]*100/dval.shape[0]\n",
    "\n",
    "        #sys.stdout.write('\\r')\n",
    "        #sys.stdout.write('\\tRMSLE T: {:.4f}\\tRMSLE V: {:.4f}\\tRowsPct: {:.4f}\\tACC. RSMLE TRAIN: {:.4f}\\tACC. RSMLE VAL: {:.4f}'.format(\n",
    "        #       rsmle_train, rsmle_val ,rows_pct, acc_rsmle_train, acc_rsmle_val))\n",
    "        #sys.stdout.flush()\n",
    "\n",
    "        \n",
    "    #For some reason this function is adding to NaN rows at the beggining, I don't know why, but we'll remove them\n",
    "    train_predictions.dropna(axis=0, how='any',inplace=True)\n",
    "    val_predictions.dropna(axis=0, how='any',inplace=True)\n",
    "    test_predictions.dropna(axis=0, how='any',inplace=True)\n",
    "    \n",
    "    return train_predictions, val_predictions, test_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_submit(dtrain, dval, dtest, filename):\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print ('RMSLE TRAIN: ', np.sqrt(metrics.mean_squared_error(dtrain[target], dtrain[\"predictions\"])))\n",
    "    print ('RMSLE VAL: ', np.sqrt(metrics.mean_squared_error(dval[target], dval[\"predictions\"])))\n",
    "    \n",
    "    #Predict on testing data: we need to revert it back to target by applying expm1\n",
    "    dtest[target] = np.expm1(dtest[target])\n",
    "    dtest[target] = np.maximum(dtest[target], 0) # we make all negative numbers = 0 since there cannot be a negative demand\n",
    "  \n",
    "    \n",
    "    print ('NUM ROWS PREDICTED: ', dtest.shape[0] )\n",
    "    print ('NUM NEGATIVES PREDICTED: ', dtest[target][dtest[target] < 0].count())\n",
    "    print ('MIN TARGET PREDICTED: ', dtest[target].min())\n",
    "    print ('MEAN TARGET PREDICTED: ', dtest[target].mean())\n",
    "    print ('MAX TARGET PREDICTED: ', dtest[target].max())\n",
    "    \n",
    "    #Export submission file:\n",
    "    submission = dtest.copy()\n",
    "    submission[IDcol] = submission[IDcol].astype(int)\n",
    "    submission.rename(columns={target: 'Demanda_uni_equil'}, inplace=True)\n",
    "    submission.to_csv(\"./Submissions/\"+filename, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In case there is no validation, we make val = train\n",
    "if not (use_validation):\n",
    "    val = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alg6 - XGB - Train each client cluster separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try training each of the client clusters separately and see if we have good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [09:31<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "RMSLE TRAIN:  0.435551895662\n",
      "RMSLE VAL:  0.495183113214\n",
      "NUM ROWS PREDICTED:  6999251\n",
      "NUM NEGATIVES PREDICTED:  0\n",
      "MIN TARGET PREDICTED:  0.0\n",
      "MEAN TARGET PREDICTED:  4.978147328874419\n",
      "MAX TARGET PREDICTED:  1721.07685618\n",
      "Time passed: 0hour:10min:8sec\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt8AAAHfCAYAAACI4rRZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAG5CzfDdnQ+kH1FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f496aa103c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors = ['Producto_ID_clust_ID', 'Lags_sum', 'Producto_ID', 'prodtype_cluster', 'Canal_ID', 'Qty_Ruta_SAK_Bin', 'brand',\n",
    "             'Ruta_SAK', 'ZipCode']              \n",
    "for i in range(1,lag):\n",
    "    predictors.insert(0,'Log_Target_mean_lag{}'.format(i))\n",
    " \n",
    "\n",
    "model = xgb.XGBRegressor(n_estimators = 400, objective=\"reg:linear\", learning_rate= 0.1, max_depth=5,\n",
    "                         subsample=0.85,colsample_bytree=0.8, min_child_weight = 1, gamma = 0.1, scale_pos_weight = 1)\n",
    "\n",
    "tic()\n",
    "dt, dv, dte = clusters_fit(model, train, val, test, predictors, target, IDcol)\n",
    "report_submit(dt, dv, dte, 'alg6_{}.csv'.format(sufix))\n",
    "tac()\n",
    "\n",
    "#Plot Histogram of target and prediction distributions\n",
    "plt.hist(dv['log_target'], 100, alpha=0.5, label='target')\n",
    "plt.hist(dv['predictions'], 100, alpha=0.5, label='predictions') \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alg7 - XGB - Train only one batch\n",
    "\n",
    "And now let's compare it with training the complete training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = ['Producto_ID_clust_ID', 'Lags_sum', 'Producto_ID', 'prodtype_cluster', 'Canal_ID', 'Qty_Ruta_SAK_Bin', 'brand',\n",
    "             'Ruta_SAK', 'ZipCode']              \n",
    "for i in range(1,lag):\n",
    "    predictors.insert(0,'Log_Target_mean_lag{}'.format(i))\n",
    "    \n",
    "model = xgb.XGBRegressor(n_estimators = 500, objective=\"reg:linear\", learning_rate= 0.1, max_depth=10,\n",
    "                         subsample=0.85,colsample_bytree=0.7)\n",
    "\n",
    "#model = xgb.XGBRegressor(n_estimators = 1, objective=\"reg:linear\", learning_rate= 0.1, max_depth=5,\n",
    "#                         subsample=0.85,colsample_bytree=0.8, min_child_weight = 1, gamma = 0.1, scale_pos_weight = 1)\n",
    "\n",
    "tic()\n",
    "dt, dv, dte = model_fit(model, train, val, test, predictors, target, IDcol)\n",
    "report_submit(dt, dv, dte, 'alg7_{}.csv'.format(sufix))\n",
    "tac()\n",
    "\n",
    "feat_imp = pd.Series(model.booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "\n",
    "#Plot Histogram of target and prediction distributions\n",
    "plt.hist(val['log_target'], 100, alpha=0.5, label='target')\n",
    "plt.hist(val['predictions'], 100, alpha=0.5, label='predictions') \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "#Plot Training and Validation scoring\n",
    "plt.plot(model.evals_result()['validation_0']['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
