{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Building in XGBoost\n",
    "\n",
    "This is a great article for tunning XGboost: http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "windows=False\n",
    "if (windows):\n",
    "    mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "    os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "import math\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60) \n",
    "    print('Time passed: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_validation=True\n",
    "scale_numericals=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sufix: _holdout\n",
      "Time passed: 0hour:0min:51sec\n"
     ]
    }
   ],
   "source": [
    "#now we load our modified train and test set\n",
    "tic()\n",
    "sufix=\"\"\n",
    "if (use_validation): sufix += \"_holdout\"\n",
    "if (scale_numericals): sufix += \"_scaled\"\n",
    "print (\"sufix: \"+sufix)\n",
    "\n",
    "train = pd.read_csv(\"./input-data/train_modified\"+sufix+\".csv\",\n",
    "                    dtype = {'Canal_ID': 'int8',\n",
    "                            'log_target':  'float64',\n",
    "                            'Log_Target_mean_lag1': 'float64',\n",
    "                            'Log_Target_mean_lag2': 'float64',\n",
    "                            'Log_Target_mean_lag3': 'float64',\n",
    "                            'Log_Target_mean_lag4': 'float64',\n",
    "                            'Log_Target_mean_lag5': 'float64',\n",
    "                            'Lags_sum': 'float64',\n",
    "                            'pairs_mean':  'float64',\n",
    "                            'brand': 'int8',\n",
    "                            'prodtype_cluster': 'int32',\n",
    "                            'Qty_Ruta_SAK_Bin': 'int32',\n",
    "                            'ZipCode': 'uint32',\n",
    "                            'week_ct': 'int8',\n",
    "                            'NombreCliente': 'int32',\n",
    "                            'Producto_ID_clust_ID':'int32',\n",
    "                            'Ruta_SAK_clust_ID':'int32',\n",
    "                            'Agencia_ID_clust_ID':'int32',\n",
    "                            'Cliente_ID_clust_ID':'int32'},\n",
    "                   )\n",
    "                  \n",
    "val = pd.read_csv(\"./input-data/val_modified\"+sufix+\".csv\",\n",
    "                    dtype = {'Canal_ID': 'int8',\n",
    "                            'log_target':  'float64',\n",
    "                            'Log_Target_mean_lag1': 'float64',\n",
    "                            'Log_Target_mean_lag2': 'float64',\n",
    "                            'Log_Target_mean_lag3': 'float64',\n",
    "                            'Log_Target_mean_lag4': 'float64',\n",
    "                            'Log_Target_mean_lag5': 'float64',\n",
    "                            'Lags_sum': 'float64',\n",
    "                            'pairs_mean':  'float64',\n",
    "                            'brand': 'int8',\n",
    "                            'prodtype_cluster': 'int32',\n",
    "                            'Qty_Ruta_SAK_Bin': 'int32',\n",
    "                            'ZipCode': 'uint32',\n",
    "                            'week_ct': 'int8',\n",
    "                            'NombreCliente': 'int32',\n",
    "                            'Producto_ID_clust_ID':'int32',\n",
    "                            'Ruta_SAK_clust_ID':'int32',\n",
    "                            'Agencia_ID_clust_ID':'int32',\n",
    "                            'Cliente_ID_clust_ID':'int32'},\n",
    "                   ) \n",
    "    \n",
    "test = pd.read_csv(\"./input-data/test_modified\"+sufix+\".csv\",\n",
    "                    dtype = {'id': 'uint32',\n",
    "                            'Canal_ID': 'int8',\n",
    "                            'Log_Target_mean_lag1': 'float64',\n",
    "                            'Log_Target_mean_lag2': 'float64',\n",
    "                            'Log_Target_mean_lag3': 'float64',\n",
    "                            'Log_Target_mean_lag4': 'float64',\n",
    "                            'Log_Target_mean_lag5': 'float64',\n",
    "                            'Lags_sum': 'float64',\n",
    "                            'pairs_mean':  'float64',\n",
    "                            'brand': 'int8',\n",
    "                            'prodtype_cluster': 'int32',\n",
    "                            'Qty_Ruta_SAK_Bin': 'int32',\n",
    "                            'ZipCode': 'uint32',\n",
    "                            'week_ct': 'int8',\n",
    "                            'NombreCliente': 'int32',\n",
    "                            'Producto_ID_clust_ID':'int32',\n",
    "                            'Ruta_SAK_clust_ID':'int32',\n",
    "                            'Agencia_ID_clust_ID':'int32',\n",
    "                            'Cliente_ID_clust_ID':'int32'},\n",
    "                      )\n",
    "tac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define target and ID columns:\n",
    "target = 'log_target'\n",
    "IDcol = 'id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train multiple models per client cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we said on our prior step (Models wiht scikit-learn) that we need to deal with the data set high variance. Let's do this first:\n",
    "\n",
    "Looking at the plot below, created on the clustering-by-demand on the feature engineering notebook, we see that some client clusters behave very differntly from others. So this explain why our model is failing on predicting accurately for all of them.\n",
    "We are going then to create a wrapper function to create as many models as Client Clusters by demand are (Cliente_ID_clust_ID). The scores should be bettter individually, and the concatenation of all 400 models should yield a better overall RSMLE than our baseline 0.47.\n",
    "\n",
    "![Image of Variables vs Hypothesis](./input-data/h2o-clustByDem_Cliente_ID_400.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def modelfit(alg, ctrain, cval, ctest, predictors, target, IDcol):\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    watchlist = [(cval[predictors], cval[target])]\n",
    "    alg.fit(ctrain[predictors], ctrain[target], eval_set=watchlist, eval_metric='rmse', early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    alg.evals_result()\n",
    "\n",
    "    #Predict training set:\n",
    "    ctrain[\"predictions\"] = alg.predict(ctrain[predictors])\n",
    "    ctrain[\"predictions\"] = np.maximum(ctrain[\"predictions\"], 0)\n",
    "\n",
    "    \n",
    "    #Predict validation (holdout) set:\n",
    "    cval[\"predictions\"] = alg.predict(cval[predictors])\n",
    "    cval[\"predictions\"] = np.maximum(cval[\"predictions\"], 0)# we make all negative numbers = 0 since there cannot be a negative demand\n",
    "\n",
    "    \n",
    "    #Predict on testing data: we need to revert it back to target by applying expm1\n",
    "    ctest[target] = alg.predict(ctest[predictors])\n",
    "    ctest[target] = np.maximum(ctest[target], 0) # we make all negative numbers = 0 since there cannot be a negative demand\n",
    "    \n",
    "    print ('RMSLE VAL: ', np.sqrt(metrics.mean_squared_error(cval[target].values, cval[\"predictions\"].values)))\n",
    "    \n",
    "    return ctrain[[target,\"predictions\"]], cval[[target,\"predictions\"]], ctest[[IDcol,target]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clusters_fit (alg, dtrain, dval, dtest, predictors, target, IDcol, filepath):\n",
    "    \n",
    "    train_predictions = pd.DataFrame(index=[target,\"predictions\"])\n",
    "    val_predictions = pd.DataFrame(index=[target,\"predictions\"])\n",
    "    test_predictions = pd.DataFrame(index=[IDcol,target])\n",
    "    \n",
    "    clusters_list = train.Cliente_ID_clust_ID.drop_duplicates().get_values()\n",
    "    \n",
    "    for cluster in clusters_list:\n",
    "        \n",
    "        #we get the cluster train,val, test data\n",
    "        ctrain = dtrain.loc[dtrain[\"Cliente_ID_clust_ID\"] == cluster]\n",
    "        cval   = dval.loc[dval[\"Cliente_ID_clust_ID\"] == cluster]\n",
    "        ctest  = dtest.loc[dtest[\"Cliente_ID_clust_ID\"] == cluster]\n",
    "        \n",
    "        #we train the cluster\n",
    "        ctrain, cval, ctest = modelfit(model, ctrain, cval, ctest, predictors, target, IDcol)\n",
    "        \n",
    "        #concatenate each cluster result\n",
    "        train_predictions = pd.concat([train_predictions,ctrain],ignore_index=True)\n",
    "        val_predictions = pd.concat([val_predictions,cval],ignore_index=True)\n",
    "        test_predictions = pd.concat([test_predictions,ctest],ignore_index=True)\n",
    "        \n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print ('RMSLE TRAIN: ', np.sqrt(metrics.mean_squared_error(dtrain[target].values, train_predictions[target])))\n",
    "    print ('RMSLE VAL: ', np.sqrt(metrics.mean_squared_error(dval[target].values, val_predictions[target])))\n",
    "    \n",
    "    #Predict on testing data: we need to revert it back to target by applying expm1\n",
    "    test_predictions[target] = np.expm1(test_predictions[target])\n",
    "    test_predictions[target] = np.maximum(test_predictions[target], 0) # we make all negative numbers = 0 since there cannot be a negative demand\n",
    "  \n",
    "    \n",
    "    print ('NUM ROWS PREDICTED: ', test_predictions.shape[0] )\n",
    "    print ('NUM NEGATIVES PREDICTED: ', test_predictions[target][test_predictions[target] < 0].count())\n",
    "    print ('MIN TARGET PREDICTED: ', test_predictions[target].min())\n",
    "    print ('MEAN TARGET PREDICTED: ', test_predictions[target].mean())\n",
    "    print ('MAX TARGET PREDICTED: ', test_predictions[target].max())\n",
    "    \n",
    "    #Export submission file:\n",
    "    submission = test_predictions.copy()\n",
    "    submission[IDcol] = submission[IDcol].astype(int)\n",
    "    submission.rename(columns={target: 'Demanda_uni_equil'}, inplace=True)\n",
    "    submission.to_csv(\"./Submissions/\"+filename, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alg10 - XGB-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the behavior of the random forest sckit-learn model (our best so far with score of 0.47), let's borrow some parameters from it, and see if we have improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE VAL:  0.504476809774\n",
      "RMSLE VAL:  0.411533214317\n",
      "RMSLE VAL:  0.43973570085\n",
      "RMSLE VAL:  0.411024145431\n",
      "RMSLE VAL:  0.538882143992\n",
      "RMSLE VAL:  0.457453228549\n",
      "RMSLE VAL:  0.454718086982\n",
      "RMSLE VAL:  0.524101808507\n",
      "RMSLE VAL:  0.480459504838\n",
      "RMSLE VAL:  0.559216601161\n",
      "RMSLE VAL:  0.463009332224\n",
      "RMSLE VAL:  0.539271713866\n",
      "RMSLE VAL:  0.450717040962\n",
      "RMSLE VAL:  0.533560039429\n",
      "RMSLE VAL:  0.657766196204\n",
      "RMSLE VAL:  0.427734832854\n",
      "RMSLE VAL:  0.47998707625\n",
      "RMSLE VAL:  0.534321323108\n",
      "RMSLE VAL:  0.451141760502\n",
      "RMSLE VAL:  0.510919086283\n",
      "RMSLE VAL:  0.452260572799\n",
      "RMSLE VAL:  0.710465530112\n",
      "RMSLE VAL:  0.474813833156\n",
      "RMSLE VAL:  0.467305759094\n",
      "RMSLE VAL:  0.342479978786\n",
      "RMSLE VAL:  0.481005957126\n",
      "RMSLE VAL:  0.591958551938\n",
      "RMSLE VAL:  0.485771621916\n",
      "RMSLE VAL:  0.533540321496\n",
      "RMSLE VAL:  0.464081499086\n",
      "RMSLE VAL:  0.474319668149\n",
      "RMSLE VAL:  0.455628824345\n",
      "RMSLE VAL:  0.462235740914\n",
      "RMSLE VAL:  0.717501410431\n",
      "RMSLE VAL:  0.787615656434\n",
      "RMSLE VAL:  0.560629010909\n",
      "RMSLE VAL:  0.546398959646\n",
      "RMSLE VAL:  0.654519234868\n",
      "RMSLE VAL:  0.571010909926\n",
      "RMSLE VAL:  0.701718843065\n",
      "RMSLE VAL:  0.460753892335\n",
      "RMSLE VAL:  0.608181734098\n",
      "RMSLE VAL:  0.573440029737\n",
      "RMSLE VAL:  0.407864590572\n",
      "RMSLE VAL:  0.336757657212\n",
      "RMSLE VAL:  0.613611688483\n",
      "RMSLE VAL:  0.442385485081\n",
      "RMSLE VAL:  0.685498154799\n",
      "RMSLE VAL:  0.611652381401\n",
      "RMSLE VAL:  0.52561032496\n",
      "RMSLE VAL:  0.568635957514\n",
      "RMSLE VAL:  0.69074220005\n",
      "RMSLE VAL:  0.583459369435\n",
      "RMSLE VAL:  0.829771270615\n",
      "RMSLE VAL:  1.15170321932\n",
      "RMSLE VAL:  0.586032692412\n",
      "RMSLE VAL:  0.534387247023\n",
      "RMSLE VAL:  0.524279055618\n",
      "RMSLE VAL:  0.540410066901\n",
      "RMSLE VAL:  0.550885086574\n",
      "RMSLE VAL:  0.739431811515\n",
      "RMSLE VAL:  0.427716146791\n",
      "RMSLE VAL:  0.431530939265\n",
      "RMSLE VAL:  0.487528550249\n",
      "RMSLE VAL:  0.541126760413\n",
      "RMSLE VAL:  0.81548597094\n",
      "RMSLE VAL:  0.488070920198\n",
      "RMSLE VAL:  0.4656165077\n",
      "RMSLE VAL:  0.834928059551\n",
      "RMSLE VAL:  0.510760819032\n",
      "RMSLE VAL:  0.555649166607\n",
      "RMSLE VAL:  0.501941925598\n",
      "RMSLE VAL:  0.418595374752\n",
      "RMSLE VAL:  0.50718009601\n",
      "RMSLE VAL:  0.65756414259\n",
      "RMSLE VAL:  0.876880715163\n",
      "RMSLE VAL:  0.46524026825\n",
      "RMSLE VAL:  0.750158209978\n",
      "RMSLE VAL:  0.557835634468\n",
      "RMSLE VAL:  0.775004856485\n",
      "RMSLE VAL:  0.58946095591\n",
      "RMSLE VAL:  0.569512230897\n",
      "RMSLE VAL:  0.612993756597\n",
      "RMSLE VAL:  0.581338893667\n",
      "RMSLE VAL:  0.660342326006\n",
      "RMSLE VAL:  0.536243111754\n",
      "RMSLE VAL:  0.505380959052\n",
      "RMSLE VAL:  0.48747246892\n",
      "RMSLE VAL:  0.502536923199\n",
      "RMSLE VAL:  0.503240219534\n",
      "RMSLE VAL:  0.455385889901\n",
      "RMSLE VAL:  0.406236127331\n",
      "RMSLE VAL:  0.49988262977\n",
      "RMSLE VAL:  0.509290670151\n",
      "RMSLE VAL:  0.584730097631\n",
      "RMSLE VAL:  0.408514548905\n",
      "RMSLE VAL:  0.479776911521\n",
      "RMSLE VAL:  0.543215722856\n",
      "RMSLE VAL:  0.616263770331\n",
      "RMSLE VAL:  0.56743513775\n",
      "RMSLE VAL:  0.475921658451\n",
      "RMSLE VAL:  0.627514574637\n",
      "RMSLE VAL:  0.592160439207\n",
      "RMSLE VAL:  0.425841724643\n",
      "RMSLE VAL:  0.391198671255\n",
      "RMSLE VAL:  0.576504808185\n",
      "RMSLE VAL:  0.554301321441\n",
      "RMSLE VAL:  0.600476713799\n",
      "RMSLE VAL:  0.535683315535\n",
      "RMSLE VAL:  0.402945964173\n",
      "RMSLE VAL:  1.17167329803\n",
      "RMSLE VAL:  0.553154159414\n",
      "RMSLE VAL:  0.724043796673\n",
      "RMSLE VAL:  0.541239118746\n",
      "RMSLE VAL:  0.53695483601\n",
      "RMSLE VAL:  0.642497092111\n",
      "RMSLE VAL:  0.577331692768\n",
      "RMSLE VAL:  0.614108298437\n",
      "RMSLE VAL:  0.616621310828\n",
      "RMSLE VAL:  0.446901213771\n",
      "RMSLE VAL:  0.604414568061\n",
      "RMSLE VAL:  0.50219523755\n",
      "RMSLE VAL:  0.459267235843\n",
      "RMSLE VAL:  0.496176076133\n",
      "RMSLE VAL:  0.467619654775\n",
      "RMSLE VAL:  0.364554467982\n",
      "RMSLE VAL:  0.539501400187\n",
      "RMSLE VAL:  0.487156277562\n",
      "RMSLE VAL:  0.609703766621\n",
      "RMSLE VAL:  0.417617251782\n",
      "RMSLE VAL:  0.544704063695\n",
      "RMSLE VAL:  0.479608136623\n",
      "RMSLE VAL:  0.556423117934\n",
      "RMSLE VAL:  0.569353522009\n",
      "RMSLE VAL:  0.463878050102\n",
      "RMSLE VAL:  1.36000664238\n",
      "RMSLE VAL:  0.431236680444\n",
      "RMSLE VAL:  0.41515557678\n",
      "RMSLE VAL:  0.963402698958\n",
      "RMSLE VAL:  0.589013862977\n",
      "RMSLE VAL:  0.580253117295\n",
      "RMSLE VAL:  0.445863761514\n",
      "RMSLE VAL:  0.512415324543\n",
      "RMSLE VAL:  0.367914826559\n",
      "RMSLE VAL:  0.515903473733\n",
      "RMSLE VAL:  0.544796559678\n",
      "RMSLE VAL:  0.48399895873\n",
      "RMSLE VAL:  0.479129579326\n",
      "RMSLE VAL:  0.488464487162\n",
      "RMSLE VAL:  0.429648009828\n",
      "RMSLE VAL:  0.638944872904\n",
      "RMSLE VAL:  0.553839944638\n",
      "RMSLE VAL:  0.696918725718\n",
      "RMSLE VAL:  0.555111856437\n",
      "RMSLE VAL:  0.468859071676\n",
      "RMSLE VAL:  0.529988911902\n",
      "RMSLE VAL:  0.487105564277\n",
      "RMSLE VAL:  0.496857578757\n",
      "RMSLE VAL:  0.461978346849\n",
      "RMSLE VAL:  0.518317319263\n",
      "RMSLE VAL:  0.606017897225\n",
      "RMSLE VAL:  0.578183528723\n",
      "RMSLE VAL:  0.784591950026\n",
      "RMSLE VAL:  0.841300166186\n",
      "RMSLE VAL:  0.414778274213\n",
      "RMSLE VAL:  0.44372578435\n",
      "RMSLE VAL:  0.435081650519\n",
      "RMSLE VAL:  0.403004321694\n",
      "RMSLE VAL:  0.594805394596\n",
      "RMSLE VAL:  0.484476918947\n",
      "RMSLE VAL:  0.755223516409\n",
      "RMSLE VAL:  0.419753310547\n",
      "RMSLE VAL:  0.466714690159\n",
      "RMSLE VAL:  0.451024810817\n",
      "RMSLE VAL:  0.465660173424\n",
      "RMSLE VAL:  0.423187317618\n",
      "RMSLE VAL:  0.490392419552\n",
      "RMSLE VAL:  0.514617830533\n",
      "RMSLE VAL:  0.368363618521\n",
      "RMSLE VAL:  0.37118982609\n",
      "RMSLE VAL:  0.540783093278\n",
      "RMSLE VAL:  0.406686557363\n",
      "RMSLE VAL:  0.454494726736\n",
      "RMSLE VAL:  0.482339121925\n",
      "RMSLE VAL:  0.490206895308\n",
      "RMSLE VAL:  0.48328795214\n",
      "RMSLE VAL:  0.436922268297\n",
      "RMSLE VAL:  0.367814521855\n",
      "RMSLE VAL:  0.34538875908\n",
      "RMSLE VAL:  0.533922262033\n",
      "RMSLE VAL:  0.546190807706\n",
      "RMSLE VAL:  0.376716715039\n",
      "RMSLE VAL:  0.54673178648\n",
      "RMSLE VAL:  0.477688759416\n",
      "RMSLE VAL:  0.7534340698\n",
      "RMSLE VAL:  0.830876009417\n",
      "RMSLE VAL:  0.46505117113\n",
      "RMSLE VAL:  0.449844316247\n",
      "RMSLE VAL:  0.42790725327\n",
      "RMSLE VAL:  0.474360223446\n",
      "RMSLE VAL:  0.518431033643\n",
      "RMSLE VAL:  0.517610992975\n",
      "RMSLE VAL:  0.891111612842\n",
      "RMSLE VAL:  0.411044707179\n",
      "RMSLE VAL:  0.612255992668\n",
      "RMSLE VAL:  0.834324606205\n",
      "RMSLE VAL:  0.490691261954\n",
      "RMSLE VAL:  0.595499860806\n",
      "RMSLE VAL:  0.514108112095\n",
      "RMSLE VAL:  0.532483311576\n",
      "RMSLE VAL:  0.648880272634\n",
      "RMSLE VAL:  0.577392953599\n",
      "RMSLE VAL:  0.42529650479\n",
      "RMSLE VAL:  0.497995191297\n",
      "RMSLE VAL:  0.48160541998\n",
      "RMSLE VAL:  0.452404221625\n",
      "RMSLE VAL:  0.415343144915\n",
      "RMSLE VAL:  0.449219214777\n",
      "RMSLE VAL:  0.478880135638\n",
      "RMSLE VAL:  0.893289971774\n",
      "RMSLE VAL:  0.476076669596\n",
      "RMSLE VAL:  0.498998385388\n",
      "RMSLE VAL:  0.590278553704\n",
      "RMSLE VAL:  1.04985530866\n",
      "RMSLE VAL:  0.446159735024\n",
      "RMSLE VAL:  0.754387321849\n",
      "RMSLE VAL:  0.62846810232\n",
      "RMSLE VAL:  0.417927084129\n",
      "RMSLE VAL:  0.386047830458\n",
      "RMSLE VAL:  0.493843740491\n",
      "RMSLE VAL:  0.461378917208\n",
      "RMSLE VAL:  0.477362632297\n",
      "RMSLE VAL:  0.540828590736\n",
      "RMSLE VAL:  0.457873128051\n",
      "RMSLE VAL:  0.686053320321\n",
      "RMSLE VAL:  0.505925832727\n",
      "RMSLE VAL:  0.506872534642\n",
      "RMSLE VAL:  0.642103089647\n",
      "RMSLE VAL:  0.553253360567\n",
      "RMSLE VAL:  0.414197992483\n",
      "RMSLE VAL:  0.529050467889\n",
      "RMSLE VAL:  0.433099162081\n",
      "RMSLE VAL:  0.89167164075\n",
      "RMSLE VAL:  0.436539175719\n",
      "RMSLE VAL:  0.780318434082\n",
      "RMSLE VAL:  0.395222128315\n",
      "RMSLE VAL:  0.482593227598\n",
      "RMSLE VAL:  0.466181641018\n",
      "RMSLE VAL:  0.572058154499\n",
      "RMSLE VAL:  0.474560419915\n",
      "RMSLE VAL:  0.483628369391\n",
      "RMSLE VAL:  0.433171755179\n",
      "RMSLE VAL:  0.846217403521\n",
      "RMSLE VAL:  0.694177335003\n",
      "RMSLE VAL:  0.472664995973\n",
      "RMSLE VAL:  0.459617042418\n",
      "RMSLE VAL:  0.337824527786\n",
      "RMSLE VAL:  0.402111813343\n",
      "RMSLE VAL:  0.424229963773\n",
      "RMSLE VAL:  0.429427771676\n",
      "RMSLE VAL:  0.436688970216\n",
      "RMSLE VAL:  0.428583876133\n",
      "RMSLE VAL:  0.789767166926\n",
      "RMSLE VAL:  0.431424431951\n",
      "RMSLE VAL:  0.456367089016\n",
      "RMSLE VAL:  0.427613784358\n",
      "RMSLE VAL:  0.428428660481\n",
      "RMSLE VAL:  0.451933823202\n",
      "RMSLE VAL:  0.423792095218\n",
      "RMSLE VAL:  0.43040746515\n",
      "RMSLE VAL:  0.414900192961\n",
      "RMSLE VAL:  0.523883643592\n",
      "RMSLE VAL:  0.46610655483\n",
      "RMSLE VAL:  0.431220467519\n",
      "RMSLE VAL:  0.543735299221\n",
      "RMSLE VAL:  0.429515185487\n",
      "RMSLE VAL:  0.399520613708\n",
      "RMSLE VAL:  0.482962017943\n",
      "RMSLE VAL:  0.479115971744\n",
      "RMSLE VAL:  0.375536218411\n",
      "RMSLE VAL:  0.416592582583\n",
      "RMSLE VAL:  0.496850695821\n",
      "RMSLE VAL:  0.491083478018\n",
      "RMSLE VAL:  0.567947814365\n",
      "RMSLE VAL:  0.425105317589\n",
      "RMSLE VAL:  0.639846838054\n",
      "RMSLE VAL:  0.42598456814\n",
      "RMSLE VAL:  0.63251102254\n",
      "RMSLE VAL:  0.449107285275\n",
      "RMSLE VAL:  0.66243853695\n",
      "RMSLE VAL:  0.475439631222\n",
      "RMSLE VAL:  0.463320805277\n",
      "RMSLE VAL:  0.448045320272\n",
      "RMSLE VAL:  0.429060281512\n",
      "RMSLE VAL:  0.475228923889\n",
      "RMSLE VAL:  0.499030792707\n",
      "RMSLE VAL:  0.351091951503\n",
      "RMSLE VAL:  0.469330832633\n",
      "RMSLE VAL:  0.6162182188\n",
      "RMSLE VAL:  0.409380024248\n",
      "RMSLE VAL:  0.410898816166\n",
      "RMSLE VAL:  0.399819624715\n",
      "RMSLE VAL:  0.803823769838\n",
      "RMSLE VAL:  0.424078572286\n",
      "RMSLE VAL:  0.544974842462\n",
      "RMSLE VAL:  0.416000614439\n",
      "RMSLE VAL:  0.452338497471\n",
      "RMSLE VAL:  0.435201543019\n",
      "RMSLE VAL:  1.24501711158\n",
      "RMSLE VAL:  0.462243192825\n",
      "RMSLE VAL:  0.389300716828\n",
      "RMSLE VAL:  0.804903107637\n",
      "RMSLE VAL:  1.02769959298\n",
      "RMSLE VAL:  0.412527338026\n",
      "RMSLE VAL:  0.445105620896\n",
      "RMSLE VAL:  0.370979920234\n",
      "RMSLE VAL:  0.483614290079\n",
      "RMSLE VAL:  0.859097351069\n",
      "RMSLE VAL:  0.452185892205\n",
      "RMSLE VAL:  0.449363582595\n",
      "RMSLE VAL:  0.444077746235\n",
      "RMSLE VAL:  0.372256366043\n",
      "RMSLE VAL:  0.517178725178\n",
      "RMSLE VAL:  0.376254854654\n",
      "RMSLE VAL:  0.818847045554\n",
      "RMSLE VAL:  0.41194607324\n",
      "RMSLE VAL:  0.418470949642\n",
      "RMSLE VAL:  0.493492462366\n",
      "RMSLE VAL:  0.682349440518\n",
      "RMSLE VAL:  0.402821724952\n",
      "RMSLE VAL:  0.399282034996\n",
      "RMSLE VAL:  0.401068485294\n",
      "RMSLE VAL:  0.474985427488\n",
      "RMSLE VAL:  0.435952834054\n",
      "RMSLE VAL:  0.449963030059\n",
      "RMSLE VAL:  0.517648075851\n",
      "RMSLE VAL:  0.462222084111\n",
      "RMSLE VAL:  0.461643412026\n",
      "RMSLE VAL:  0.387617544092\n",
      "RMSLE VAL:  0.420479501417\n",
      "RMSLE VAL:  0.433487932029\n",
      "RMSLE VAL:  0.466990616402\n",
      "RMSLE VAL:  0.519824401393\n",
      "RMSLE VAL:  0.431789478478\n",
      "RMSLE VAL:  0.421584258218\n",
      "RMSLE VAL:  0.530726138052\n",
      "RMSLE VAL:  0.449949528201\n",
      "RMSLE VAL:  0.415347427747\n",
      "RMSLE VAL:  0.585113855734\n",
      "RMSLE VAL:  0.453319656185\n",
      "RMSLE VAL:  0.486363078892\n",
      "RMSLE VAL:  0.433604831505\n",
      "RMSLE VAL:  0.447167210291\n",
      "RMSLE VAL:  0.390677168047\n",
      "RMSLE VAL:  0.397624516188\n",
      "RMSLE VAL:  0.424339786336\n",
      "RMSLE VAL:  0.413222651001\n",
      "RMSLE VAL:  0.43681726839\n",
      "RMSLE VAL:  0.427713385145\n",
      "RMSLE VAL:  0.430587064292\n",
      "RMSLE VAL:  0.494219778922\n",
      "RMSLE VAL:  0.444981634644\n",
      "RMSLE VAL:  0.366497310486\n",
      "RMSLE VAL:  0.517788648446\n",
      "RMSLE VAL:  0.412829447154\n",
      "RMSLE VAL:  0.422600477593\n",
      "RMSLE VAL:  0.470000845295\n",
      "RMSLE VAL:  0.472679644767\n",
      "RMSLE VAL:  0.428726692921\n",
      "RMSLE VAL:  0.431601798851\n",
      "RMSLE VAL:  0.468185615816\n",
      "RMSLE VAL:  0.441259788603\n",
      "RMSLE VAL:  0.443439397316\n",
      "RMSLE VAL:  0.464480352475\n",
      "RMSLE VAL:  0.458249360556\n",
      "RMSLE VAL:  0.409239502482\n",
      "RMSLE VAL:  0.545439423253\n",
      "RMSLE VAL:  0.483661464894\n",
      "RMSLE VAL:  0.459218375624\n",
      "RMSLE VAL:  0.453055521226\n",
      "RMSLE VAL:  0.445024377428\n",
      "RMSLE VAL:  0.467706551134\n",
      "RMSLE VAL:  0.422426302704\n",
      "RMSLE VAL:  0.417973665048\n",
      "RMSLE VAL:  0.441712662147\n",
      "RMSLE VAL:  0.460619145525\n",
      "RMSLE VAL:  0.439171132061\n",
      "RMSLE VAL:  0.488702888726\n",
      "RMSLE VAL:  0.468923561687\n",
      "RMSLE VAL:  0.423315827033\n",
      "RMSLE VAL:  0.437218972607\n",
      "RMSLE VAL:  0.453222989483\n",
      "RMSLE VAL:  0.433755117301\n",
      "RMSLE VAL:  0.460321568473\n",
      "RMSLE VAL:  0.436732092141\n",
      "RMSLE VAL:  0.415816727855\n",
      "RMSLE VAL:  1.27556906059\n",
      "RMSLE VAL:  0.433279294562\n",
      "RMSLE VAL:  0.457333302697\n",
      "RMSLE VAL:  0.918903947924\n",
      "\n",
      "Model Report\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [10406868 10406870]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-83177abb1de1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mclusters_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIDcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'alg10.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mtac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-02be058d44b3>\u001b[0m in \u001b[0;36mclusters_fit\u001b[1;34m(alg, dtrain, dval, dtest, predictors, target, IDcol, filepath)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m#Print model report:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nModel Report\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'RMSLE TRAIN: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'RMSLE VAL: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m    230\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 231\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    232\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[0;32m    233\u001b[0m                                weights=sample_weight)\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[1;32m--> 176\u001b[1;33m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [10406868 10406870]"
     ]
    }
   ],
   "source": [
    "predictors = ['Canal_ID', 'Log_Target_mean_lag1', 'Log_Target_mean_lag2', 'Log_Target_mean_lag3', 'Log_Target_mean_lag4', \n",
    "              'Log_Target_mean_lag5','Lags_sum', 'brand', 'prodtype_cluster', 'Qty_Ruta_SAK_Bin', 'ZipCode', 'Producto_ID_clust_ID']\n",
    "\n",
    "\n",
    "model = xgb.XGBRegressor(n_estimators = 50, objective=\"reg:linear\", learning_rate= 0.1, max_depth=10,\n",
    "                         subsample=0.85,colsample_bytree=0.7)\n",
    "\n",
    "tic()\n",
    "clusters_fit(model, train, val, test, predictors, target, IDcol, 'alg10.csv')\n",
    "tac()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great improvement from past algos. The most important thing that I see here is that the Feature importance map\n",
    "is very different from the H2O models. LB Scores between XGB and H2O are similar, so this is a great case for ensembling!\n",
    "\n",
    "Let's try more estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
